{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa8ff4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch_version: 1.13.1+cu117\n",
      "functorch_version: 1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/nvfuser_intro_tutorial.html\n",
    "# Authors: \n",
    "#     Christian Sarofeen > https://github.com/csarofeen\n",
    "#     Piotr Bialecki > https://github.com/ptrblck\n",
    "#     Kevin Stephano > https://github.com/kevinstephano\n",
    "#     Jie Jiang > https://github.com/jjsjann123\n",
    "#     Masaki Kozuki https://github.com/crcrpar\n",
    "#     Neal Vaidya\n",
    "#     IvanYashchuk https://github.com/IvanYashchuk > https://twitter.com/IvanYashchuk\n",
    "#     Svetlana Karslioglu https://github.com/svekars > \n",
    "    \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import functorch\n",
    "from functorch.compile import memory_efficient_fusion\n",
    "from copy import deepcopy\n",
    "from typing import List\n",
    "import time\n",
    "import functools\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "torch_version = torch.__version__\n",
    "print(f'torch_version: {torch_version}')\n",
    "if torch_version < (1, 12, 0):\n",
    "    raise RuntimeError(\n",
    "        \"PyTorch >= 1.12.0 required, but your environment uses torch=={}\".format(\n",
    "            torch.__version__\n",
    "        )\n",
    "    )\n",
    "\n",
    "functorch_version = functorch.__version__\n",
    "print(f'functorch_version: {functorch_version}')\n",
    "major, minor, cuda_version = functorch_version.split(\".\")\n",
    "if int(major) == 0 and int(minor) < 2:\n",
    "    raise RuntimeError(\n",
    "        \"FuncTorch >= 0.2.0 required, but your environment uses functorch=={}\".format(\n",
    "            functorch.__version__\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6454f442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_definition(\n",
    "    input1: torch.Tensor,\n",
    "    input2: torch.Tensor,\n",
    "    weight: torch.Tensor,\n",
    "    bias1: torch.Tensor,\n",
    "    bias2: torch.Tensor,\n",
    "    normalization_axis: int,\n",
    "    dropout_prob: float,\n",
    ") -> torch.Tensor:\n",
    "    bias1_out = input1 + bias1\n",
    "    dropout_out = F.dropout(bias1_out, dropout_prob, training=True)\n",
    "    norm_input = dropout_out + input2\n",
    "    norm_output = F.layer_norm(\n",
    "        norm_input, (input1.size(normalization_axis),), weight, bias2\n",
    "    )\n",
    "    return norm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "446c1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup initial tensors and parameters\n",
    "input_size = [64, 128, 1024]\n",
    "device = \"cuda\"\n",
    "dtype = torch.float32\n",
    "\n",
    "# Create sample inputs\n",
    "input1 = torch.randn(*input_size, device=device, dtype=dtype, requires_grad=True)\n",
    "input2 = torch.rand_like(input1).requires_grad_()\n",
    "\n",
    "# Precompute a grad output tensor, for this example it's the same size\n",
    "# as the inputs\n",
    "grad_output = torch.rand_like(input1)\n",
    "\n",
    "# Randomly initialize the model parameters\n",
    "weight = torch.nn.Parameter(torch.randn(input_size[2], dtype=dtype, device=device))\n",
    "bias1 = torch.nn.Parameter(torch.randn(input_size[2], dtype=dtype, device=device))\n",
    "bias2 = torch.nn.Parameter(torch.randn(input_size[2], dtype=dtype, device=device))\n",
    "\n",
    "parameters = [input1, input2, weight, bias1, bias2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f585fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to profile the workload\n",
    "def profile_workload(forward_func, grad_output, iteration_count=100, label=\"\"):\n",
    "    # Perform warm-up iterations\n",
    "    for _ in range(3):\n",
    "        # Run model, forward and backward\n",
    "        output = forward_func()\n",
    "        output.backward(grad_output)\n",
    "        # delete gradiens to avoid profiling the gradient accumulation\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "\n",
    "    # Synchronize the GPU before starting the timer\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(iteration_count):\n",
    "        # Run model, forward and backward\n",
    "        output = forward_func()\n",
    "        output.backward(grad_output)\n",
    "        # delete gradiens to avoid profiling the gradient accumulation\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "\n",
    "    # Synchronize the GPU before stopping the timer\n",
    "    torch.cuda.synchronize()\n",
    "    stop = time.perf_counter()\n",
    "    iters_per_second = iteration_count / (stop - start)\n",
    "    if label:\n",
    "        print(label)\n",
    "    print(\"Average iterations per second: {:.2f}\".format(iters_per_second))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83bb9c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager Mode - Composite definition\n",
      "Average iterations per second: 216.45\n"
     ]
    }
   ],
   "source": [
    "# Run and profile eager mode execution on the composite definition of our\n",
    "# operations.\n",
    "func = functools.partial(\n",
    "    composite_definition,\n",
    "    input1,\n",
    "    input2,\n",
    "    weight,\n",
    "    bias1,\n",
    "    bias2,\n",
    "    normalization_axis=2,\n",
    "    dropout_prob=0.1,\n",
    ")\n",
    "profile_workload(\n",
    "    func, grad_output, iteration_count=100, label=\"Eager Mode - Composite definition\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b35cad",
   "metadata": {},
   "source": [
    "### TorchScript & nvFuser\n",
    "nvFuser is the default fusion system in TorchScript since PyTorch version 1.12, so to turn on nvFuser we need to enable TorchScript. This will allow nvFuser to automatically generate fast kernels and take over execution of these operations. TorchScript can be a challenging system to get working, but with our current definition of our operators, all we need to do is wrap our function in the torch.jit.script compile function. We can then simply run our workload as before.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fcdcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchScript - Composite definition\n",
      "Average iterations per second: 344.64\n"
     ]
    }
   ],
   "source": [
    "scripted_composite_definition = torch.jit.script(composite_definition)\n",
    "func = functools.partial(\n",
    "    scripted_composite_definition,\n",
    "    input1,\n",
    "    input2,\n",
    "    weight,\n",
    "    bias1,\n",
    "    bias2,\n",
    "    normalization_axis=2,\n",
    "    dropout_prob=0.1,\n",
    ")\n",
    "profile_workload(\n",
    "    func, grad_output, iteration_count=100, label=\"TorchScript - Composite definition\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941583c3",
   "metadata": {},
   "source": [
    "nvFuser & Dynamic Shapes\n",
    "It is challenging for Deep Learning Compilers to provide performance gains when the user changes the input sizes of the tensors. However, supporting changing shapes has always been a fundamental design criteria for nvFuser, as processing different-sized input tensors is critical to many applications like Natural Language Processing and Graph Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "799e9175",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE_COUNT = 20\n",
    "dynamic_sizes = deepcopy(input_size)\n",
    "\n",
    "inputs1: List[torch.Tensor] = []\n",
    "inputs2: List[torch.Tensor] = []\n",
    "grad_outputs: List[torch.Tensor] = []\n",
    "\n",
    "\n",
    "# Create some random shapes\n",
    "for _ in range(SHAPE_COUNT):\n",
    "    dynamic_sizes[0] = input_size[0] + random.randrange(-2, 3)\n",
    "    dynamic_sizes[1] = input_size[1] + random.randrange(-2, 3)\n",
    "    input = torch.randn(*dynamic_sizes, device=device, dtype=dtype, requires_grad=True)\n",
    "    inputs1.append(input)\n",
    "    inputs2.append(torch.rand_like(input))\n",
    "    grad_outputs.append(torch.rand_like(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b44a029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform warm-up iterations\n",
    "for _ in range(3):\n",
    "    dynamic_input1 = inputs1[0]\n",
    "    dynamic_input2 = inputs2[0]\n",
    "    dynamic_grad_output = grad_outputs[0]\n",
    "    # Run model, forward and backward\n",
    "    output = scripted_composite_definition(\n",
    "        dynamic_input1,\n",
    "        dynamic_input2,\n",
    "        weight,\n",
    "        bias1,\n",
    "        bias2,\n",
    "        normalization_axis=2,\n",
    "        dropout_prob=0.1,\n",
    "    )\n",
    "    output.backward(dynamic_grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c55b0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchScript - Random Sizes\n",
      "Average iterations per second: 376.99\n"
     ]
    }
   ],
   "source": [
    "# Profile manually as our helper function expects static inputs\n",
    "iteration_count = 100\n",
    "# Synchronize the GPU before starting the timer\n",
    "torch.cuda.synchronize()\n",
    "start = time.perf_counter()\n",
    "for i in range(iteration_count):\n",
    "    dynamic_input1 = inputs1[i % SHAPE_COUNT]\n",
    "    dynamic_input2 = inputs2[i % SHAPE_COUNT]\n",
    "    dynamic_grad_output = grad_outputs[i % SHAPE_COUNT]\n",
    "    dynamic_parameters = [dynamic_input1, dynamic_input2, weight, bias1, bias2]\n",
    "\n",
    "    # Run model, forward and backward\n",
    "    output = scripted_composite_definition(\n",
    "        dynamic_input1,\n",
    "        dynamic_input2,\n",
    "        weight,\n",
    "        bias1,\n",
    "        bias2,\n",
    "        normalization_axis=2,\n",
    "        dropout_prob=0.1,\n",
    "    )\n",
    "    output.backward(dynamic_grad_output)\n",
    "    # Delete the gradients to avoid profiling the gradient accumulation\n",
    "    for p in dynamic_parameters:\n",
    "        p.grad = None\n",
    "\n",
    "# Synchronize the GPU before stopping the timer\n",
    "torch.cuda.synchronize()\n",
    "stop = time.perf_counter()\n",
    "iters_per_second = iteration_count / (stop - start)\n",
    "print(\"TorchScript - Random Sizes\")\n",
    "print(\"Average iterations per second: {:.2f}\".format(iters_per_second))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe5ff2d",
   "metadata": {},
   "source": [
    "### Defining novel operations with nvFuser and FuncTorch\n",
    "One of the primary benefits of nvFuser is the ability to define novel operations composed of PyTorch “primitives” which are then just-in-time compiled into efficient kernels.\n",
    "\n",
    "PyTorch has strong performance for any individual operation, especially composite operations like LayerNorm. However, if LayerNorm wasn’t already implemented in PyTorch as a composite operation, then you’d have to define it as a series of simpler (primitive) operations. Let’s make such a definition and run it without nvFuser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76f74589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager Mode - Primitive Definition\n",
      "Average iterations per second: 65.23\n"
     ]
    }
   ],
   "source": [
    "def primitive_definition(\n",
    "    input1: torch.Tensor,\n",
    "    input2: torch.Tensor,\n",
    "    weight: torch.Tensor,\n",
    "    bias1: torch.Tensor,\n",
    "    bias2: torch.Tensor,\n",
    "    normalization_axis: int,\n",
    "    dropout_prob: float,\n",
    "    keepdim: bool,\n",
    ") -> torch.Tensor:\n",
    "    bias1_out = input1 + bias1\n",
    "    dropout_out = F.dropout(bias1_out, dropout_prob, training=True)\n",
    "    norm_input = dropout_out + input2\n",
    "    mean = norm_input.mean(normalization_axis, keepdim=keepdim)\n",
    "    diff = norm_input - mean\n",
    "    diff_sq = diff * diff\n",
    "    var = diff_sq.mean(normalization_axis, keepdim=keepdim)\n",
    "    pre_shift_scale_norm_output = (norm_input - mean) / torch.sqrt(var + 1e-12)\n",
    "    norm_output = weight * pre_shift_scale_norm_output + bias2\n",
    "    return norm_output\n",
    "\n",
    "\n",
    "# Profile primitive definition\n",
    "func = functools.partial(\n",
    "    primitive_definition,\n",
    "    input1,\n",
    "    input2,\n",
    "    weight,\n",
    "    bias1,\n",
    "    bias2,\n",
    "    normalization_axis=2,\n",
    "    dropout_prob=0.1,\n",
    "    keepdim=True,\n",
    ")\n",
    "profile_workload(\n",
    "    func, grad_output, iteration_count=100, label=\"Eager Mode - Primitive Definition\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a56f2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchScript - Primitive definition\n",
      "Average iterations per second: 187.01\n"
     ]
    }
   ],
   "source": [
    "# Profile scripted primitive definition\n",
    "scripted_primitive_definition = torch.jit.script(primitive_definition)\n",
    "func = functools.partial(\n",
    "    scripted_primitive_definition,\n",
    "    input1,\n",
    "    input2,\n",
    "    weight,\n",
    "    bias1,\n",
    "    bias2,\n",
    "    normalization_axis=2,\n",
    "    dropout_prob=0.1,\n",
    "    keepdim=True,\n",
    ")\n",
    "profile_workload(\n",
    "    func, grad_output, iteration_count=100, label=\"TorchScript - Primitive definition\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6b86be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def primitive_definition_for_memory_efficient_fusion(\n",
    "    input1: torch.Tensor,\n",
    "    input2: torch.Tensor,\n",
    "    weight: torch.Tensor,\n",
    "    bias1: torch.Tensor,\n",
    "    bias2: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    bias1_out = input1 + bias1\n",
    "    dropout_out = F.dropout(bias1_out, 0.1, training=True)\n",
    "    norm_input = dropout_out + input2\n",
    "    mean = norm_input.mean(2, keepdim=True)\n",
    "    diff = norm_input - mean\n",
    "    diff_sq = diff * diff\n",
    "    var = diff_sq.mean(2, keepdim=True)\n",
    "    pre_shift_scale_norm_output = (norm_input - mean) / torch.sqrt(var + 1e-12)\n",
    "    norm_output = weight * pre_shift_scale_norm_output + bias2\n",
    "    return norm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34d80443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxochicale/anaconda3/envs/aiVE/lib/python3.10/site-packages/torch/jit/_check.py:181: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\"The TorchScript type system doesn't support \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FuncTorch - Primitive definition\n",
      "Average iterations per second: 351.15\n"
     ]
    }
   ],
   "source": [
    "# Optimize the model with FuncTorch tracing and the memory efficiency\n",
    "# optimization pass\n",
    "memory_efficient_primitive_definition = memory_efficient_fusion(\n",
    "    primitive_definition_for_memory_efficient_fusion\n",
    ")\n",
    "\n",
    "# Profile memory efficient primitive definition\n",
    "func = functools.partial(\n",
    "    memory_efficient_primitive_definition, input1, input2, weight, bias1, bias2\n",
    ")\n",
    "profile_workload(\n",
    "    func,\n",
    "    grad_output,\n",
    "    iteration_count=100,\n",
    "    label=\"FuncTorch - Primitive definition\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a3be6",
   "metadata": {},
   "source": [
    "### Transformer Block With a Novel Normalization\n",
    "The ability to quickly execute chains of simple operations is important as not every operation has a composite operation defined in PyTorch. Previously, this meant researchers either had to define an entirely new operation in PyTorch – which takes a lot of time and knowledge of the lower-level PyTorch code as well as parallel programming – or writing the operation in simpler PyTorch ops and settling for poor performance. For example, let’s replace LayerNorm in our example with RMSNorm. Even though RMSNorm is a bit simpler than LayerNorm, it doesn’t have an existing compound operation in PyTorch. See the Root Mean Square Layer Normalization paper for more information about RMSNorm. As before, we’ll define our new transformer block with primitive PyTorch operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d377b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_rms_norm(\n",
    "    input1: torch.Tensor,\n",
    "    input2: torch.Tensor,\n",
    "    weight: torch.Tensor,\n",
    "    bias: torch.Tensor,\n",
    "    normalization_axis: int,\n",
    "    dropout_prob: float,\n",
    "    keepdim: bool,\n",
    ") -> torch.Tensor:\n",
    "    bias_out = input1 + bias\n",
    "    dropout_out = F.dropout(bias_out, dropout_prob, training=True)\n",
    "    norm_input = dropout_out + input2\n",
    "    var = norm_input.mul(norm_input).mean(normalization_axis, keepdim)\n",
    "    pre_shift_scale_norm_output = norm_input / torch.sqrt(var + 1e-12)\n",
    "    norm_output = weight * pre_shift_scale_norm_output\n",
    "    return norm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0070a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager Mode - RMS Norm\n",
      "Average iterations per second: 88.40\n"
     ]
    }
   ],
   "source": [
    "# Profile rms_norm\n",
    "func = functools.partial(\n",
    "    with_rms_norm,\n",
    "    input1,\n",
    "    input2,\n",
    "    weight,\n",
    "    bias1,\n",
    "    normalization_axis=2,\n",
    "    dropout_prob=0.1,\n",
    "    keepdim=True,\n",
    ")\n",
    "profile_workload(func, grad_output, iteration_count=100, label=\"Eager Mode - RMS Norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3348b10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchScript - RMS Norm\n",
      "Average iterations per second: 231.52\n"
     ]
    }
   ],
   "source": [
    "# Profile scripted rms_norm\n",
    "scripted_with_rms_norm = torch.jit.script(with_rms_norm)\n",
    "func = functools.partial(\n",
    "    scripted_with_rms_norm,\n",
    "    input1,\n",
    "    input2,\n",
    "    weight,\n",
    "    bias1,\n",
    "    normalization_axis=2,\n",
    "    dropout_prob=0.1,\n",
    "    keepdim=True,\n",
    ")\n",
    "profile_workload(func, grad_output, iteration_count=100, label=\"TorchScript - RMS Norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a316a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_rms_norm_for_memory_efficient_fusion(\n",
    "    input1: torch.Tensor, input2: torch.Tensor, weight: torch.Tensor, bias: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    bias_out = input1 + bias\n",
    "    dropout_out = torch.nn.functional.dropout(bias_out, 0.1)\n",
    "    norm_input = dropout_out + input2\n",
    "    var = norm_input.mul(norm_input).mean(2, keepdim=True)\n",
    "    pre_shift_scale_norm_output = norm_input / torch.sqrt(var + 1e-12)\n",
    "    norm_output = weight * pre_shift_scale_norm_output\n",
    "    return norm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49fe3937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FuncTorch - RMS Norm\n",
      "Average iterations per second: 290.35\n"
     ]
    }
   ],
   "source": [
    "# Profile memory efficient rms_norm\n",
    "memory_efficient_rms_norm = memory_efficient_fusion(\n",
    "    with_rms_norm_for_memory_efficient_fusion\n",
    ")\n",
    "func = functools.partial(memory_efficient_rms_norm, input1, input2, weight, bias1)\n",
    "profile_workload(func, grad_output, iteration_count=100, label=\"FuncTorch - RMS Norm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6979b3b6",
   "metadata": {},
   "source": [
    "Since RMSNorm is simpler than LayerNorm the performance of our new transformer block is a little higher than the primitive definition without nvFuser (354 iterations per second compared with 260 iterations per second). With TorchScript, the iterations per second increases by 2.68x and 3.36x to 952 iterations per second and 1,191 iterations per second with TorchScript and FuncTorch’s memory efficient optimization pass, respectively. The performance of this new operation nearly matches the performance of the composite Layer Norm definition with TorchScript.\n",
    "\n",
    "nvFuser is here to provide the ability to define novel operations in simple PyTorch and get performance that’s close to a highly optimized composite operation in PyTorch. We believe this will enable research into novel network topologies without paying for sometimes devastating effects on speed of training. nvFuser provides this unique ability as it’s able to analyze users’ programs to provide performance as fast as a highly hand tuned implementation, regardless of how the operations are defined. nvFuser still cannot support every operation in PyTorch, however its capabilities will continue to grow over time.\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/nvfuser_intro_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeababb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f655b20a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
